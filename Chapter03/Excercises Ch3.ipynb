{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Data Preprocessing in Python\n",
    "Learn how to effectively prepare data for successful data analytics\n",
    "    \n",
    "    AUTHOR: Dr. Roy Jafari \n",
    "\n",
    "### Chapter 3: Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excercise 1\n",
    "1)\tFrom 5 colleagues or classmates ask to provide a definition for the term data. \n",
    "\n",
    "    a)\tReport these definitions and indicate the similarity among them. \n",
    "    b)\tIn your own words, define the all-encompassing definition of data put forth in this chapter.\n",
    "    c)\tIndicate the two important aspects of the definition in b.\n",
    "    d)\tCompare the 5 definitions of data from your colleagues with the all-encompassing definitions and indicate  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excercise 2\n",
    "\n",
    "For this exercise, we are going to use covid_impact_on_airport_traffic.csv. Answer the following questions. This dataset is from Kaggle.com, use this link to see its page: https://www.kaggle.com/terenceshin/covid19s-impact-on-airport-traffic.\n",
    "The key attribute of this dataset is PercentOfBaseline which shows the ratio of air traffic in the specific day compared to pre-pandemic time (1st Feb to 15th March 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:50:27.903861Z",
     "start_time": "2024-05-16T01:50:27.476015Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'covid_impact_on_airport_traffic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcovid_impact_on_airport_traffic.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    900\u001B[0m     dialect,\n\u001B[1;32m    901\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    909\u001B[0m )\n\u001B[1;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1662\u001B[0m     f,\n\u001B[1;32m   1663\u001B[0m     mode,\n\u001B[1;32m   1664\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1665\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1666\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1667\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1668\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1669\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1670\u001B[0m )\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    860\u001B[0m             handle,\n\u001B[1;32m    861\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m    862\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[1;32m    863\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m    864\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    865\u001B[0m         )\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'covid_impact_on_airport_traffic.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('covid_impact_on_airport_traffic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a)\tWhat is the best definition of the data object for this dataset?\n",
    "    b)\tAre there any attributes in the data that only have one value? Use .unique() function to check. If there are remove them from the data and update the definition of the data object.\n",
    "    c)\tWhat type of values do the remaining attributes carry?\n",
    "    d)\tHow much statistical information the attribute ‘PercentOfBaseline’ has?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excercise 3    \n",
    "\n",
    "For this exercise, we are going to use US_Accidents.csv. Answer the following questions. This dataset is from Kaggle.com, use this link to see its page: https://www.kaggle.com/sobhanmoosavi/us-accidents.\n",
    "This dataset shows all the car accidents in the US from February 2016 to Dec 2020. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:51:35.720758Z",
     "start_time": "2024-05-16T01:51:35.666700Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'US_Accidents.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUS_Accidents.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    900\u001B[0m     dialect,\n\u001B[1;32m    901\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    909\u001B[0m )\n\u001B[1;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1662\u001B[0m     f,\n\u001B[1;32m   1663\u001B[0m     mode,\n\u001B[1;32m   1664\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1665\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1666\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1667\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1668\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1669\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1670\u001B[0m )\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    860\u001B[0m             handle,\n\u001B[1;32m    861\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m    862\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[1;32m    863\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m    864\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    865\u001B[0m         )\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'US_Accidents.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('US_Accidents.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a)\tWhat is the best definition of the data object for this dataset?\n",
    "    b)\tAre there any attributes in the data that only have one value? Use .unique() function to check. If there are remove them from the data and update the definition of the data object.\n",
    "    c)\tWhat type of values do the remaining attributes carry?\n",
    "    d)\tHow much statistical information the numerical attributes of the dataset carry?\n",
    "    e)\tCompare the statistical information of the numerical attributes and see if any of them are a candidate for data redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excercise 4 \n",
    "\n",
    "For this exercise, we are going to use fatal-police-shootings-data.csv. There are a lot of debates, discussions, dialogues, and protests happening in the US surrounding police killings. The Washington Post has been collecting data on all fatal police shootings in the US. The dataset available to the government and the public alike has date, age, gender, race, location, and other situational information of these fatal police shootings. You can read more about this data on https://www.washingtonpost.com/graphics/investigations/police-shootings-database/, and you can download the last version of the data from https://github.com/washingtonpost/data-police-shootings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:52:12.696050Z",
     "start_time": "2024-05-16T01:52:12.658244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id                name        date   manner_of_death       armed   age  \\\n0   3          Tim Elliot  2015-01-02              shot         gun  53.0   \n1   4    Lewis Lee Lembke  2015-01-02              shot         gun  47.0   \n2   5  John Paul Quintero  2015-01-03  shot and Tasered     unarmed  23.0   \n3   8     Matthew Hoffman  2015-01-04              shot  toy weapon  32.0   \n4   9   Michael Rodriguez  2015-01-04              shot    nail gun  39.0   \n\n  gender race           city state  signs_of_mental_illness threat_level  \\\n0      M    A        Shelton    WA                     True       attack   \n1      M    W          Aloha    OR                    False       attack   \n2      M    H        Wichita    KS                    False        other   \n3      M    W  San Francisco    CA                     True       attack   \n4      M    H          Evans    CO                    False       attack   \n\n          flee  body_camera  longitude  latitude  is_geocoding_exact  \n0  Not fleeing        False   -123.122    47.247                True  \n1  Not fleeing        False   -122.892    45.487                True  \n2  Not fleeing        False    -97.281    37.695                True  \n3  Not fleeing        False   -122.422    37.763                True  \n4  Not fleeing        False   -104.692    40.384                True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>date</th>\n      <th>manner_of_death</th>\n      <th>armed</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>race</th>\n      <th>city</th>\n      <th>state</th>\n      <th>signs_of_mental_illness</th>\n      <th>threat_level</th>\n      <th>flee</th>\n      <th>body_camera</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>is_geocoding_exact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Tim Elliot</td>\n      <td>2015-01-02</td>\n      <td>shot</td>\n      <td>gun</td>\n      <td>53.0</td>\n      <td>M</td>\n      <td>A</td>\n      <td>Shelton</td>\n      <td>WA</td>\n      <td>True</td>\n      <td>attack</td>\n      <td>Not fleeing</td>\n      <td>False</td>\n      <td>-123.122</td>\n      <td>47.247</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Lewis Lee Lembke</td>\n      <td>2015-01-02</td>\n      <td>shot</td>\n      <td>gun</td>\n      <td>47.0</td>\n      <td>M</td>\n      <td>W</td>\n      <td>Aloha</td>\n      <td>OR</td>\n      <td>False</td>\n      <td>attack</td>\n      <td>Not fleeing</td>\n      <td>False</td>\n      <td>-122.892</td>\n      <td>45.487</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>John Paul Quintero</td>\n      <td>2015-01-03</td>\n      <td>shot and Tasered</td>\n      <td>unarmed</td>\n      <td>23.0</td>\n      <td>M</td>\n      <td>H</td>\n      <td>Wichita</td>\n      <td>KS</td>\n      <td>False</td>\n      <td>other</td>\n      <td>Not fleeing</td>\n      <td>False</td>\n      <td>-97.281</td>\n      <td>37.695</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>Matthew Hoffman</td>\n      <td>2015-01-04</td>\n      <td>shot</td>\n      <td>toy weapon</td>\n      <td>32.0</td>\n      <td>M</td>\n      <td>W</td>\n      <td>San Francisco</td>\n      <td>CA</td>\n      <td>True</td>\n      <td>attack</td>\n      <td>Not fleeing</td>\n      <td>False</td>\n      <td>-122.422</td>\n      <td>37.763</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Michael Rodriguez</td>\n      <td>2015-01-04</td>\n      <td>shot</td>\n      <td>nail gun</td>\n      <td>39.0</td>\n      <td>M</td>\n      <td>H</td>\n      <td>Evans</td>\n      <td>CO</td>\n      <td>False</td>\n      <td>attack</td>\n      <td>Not fleeing</td>\n      <td>False</td>\n      <td>-104.692</td>\n      <td>40.384</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('fatal-police-shootings-data.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a)\tWhat is the best definition of the data object for this dataset?\n",
    "    b)\tAre there any attributes in the data that only have one value? Use .unique() function to check. If there are remove them from the data and update the definition of the data object.\n",
    "    c)\tWhat type of values do the remaining attributes carry?\n",
    "    d)\tHow much statistical information the numerical attributes of the dataset carry?\n",
    "    e)\tCompare the statistical information of the numerical attributes and see if any of them are a candidate for data redundancy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excercise 5\n",
    "For this exercise, we will be using electricity_prediction.csv. The screenshot below shows the 5 rows of this dataset and a linear regression model created to predict electricity consumption based on the weekday and daily average temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T01:52:22.820173Z",
     "start_time": "2024-05-16T01:52:22.790666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Date  Weekday  Consumption  Average Temperature\n0  1/1/2016        4      2581914                   80\n1  1/2/2016        5      2663011                   77\n2  1/3/2016        6      2725351                   78\n3  1/4/2016        0      3092978                   80\n4  1/5/2016        1      3231827                   81",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Weekday</th>\n      <th>Consumption</th>\n      <th>Average Temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1/1/2016</td>\n      <td>4</td>\n      <td>2581914</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1/2/2016</td>\n      <td>5</td>\n      <td>2663011</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1/3/2016</td>\n      <td>6</td>\n      <td>2725351</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1/4/2016</td>\n      <td>0</td>\n      <td>3092978</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1/5/2016</td>\n      <td>1</td>\n      <td>3231827</td>\n      <td>81</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "electricity_df = pd.read_csv('electricity_prediction.csv')\n",
    "electricity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T01:52:53.486029Z",
     "start_time": "2024-05-16T01:52:53.472150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Weekday  Average Temperature\n0          4                   80\n1          5                   77\n2          6                   78\n3          0                   80\n4          1                   81\n..       ...                  ...\n361        1                   81\n362        2                   81\n363        3                   81\n364        4                   81\n365        5                   81\n\n[366 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Weekday</th>\n      <th>Average Temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>1</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>2</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>3</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>4</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>5</td>\n      <td>81</td>\n    </tr>\n  </tbody>\n</table>\n<p>366 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = electricity_df[['Weekday', 'Average Temperature']]\n",
    "y = electricity_df['Consumption']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  3074181.49501588\n",
      "             Predictor   coefficient\n",
      "0              Weekday -55710.145405\n",
      "1  Average Temperature  -3476.377056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X, y)\n",
    "\n",
    "print('intercept ', lrm.intercept_)\n",
    "print(pd.DataFrame({'Predictor': X.columns, 'coefficient': lrm.coef_}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T01:53:23.492619Z",
     "start_time": "2024-05-16T01:53:23.469922Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression model that is derived from the data is presented below.\n",
    "\n",
    "    Consumption = 3074181.5- 55710.1 × Weekday-3476.4 ×Average Temperature\n",
    "\n",
    "What is the fundamental mistake in this analysis? Describe it and provides possible solutions for it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excercise 6\n",
    "For this exercise, we will be using adult.csv. we used this dataset extensively in chapter 1. Read the dataset using Padans and call it adult_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a)\tWhat type of values does the attribute eduction carry?\n",
    "    b)\tRun 'adult_df.education.unique()', study the results, and explain what the code does.\n",
    "    c)\tBased on your understandings, order the output of the code you ran for b).\n",
    "    d)\tRun 'pd.get_dummies(adult_df.education)', study the results, and explain what the code does.\n",
    "    e)\tRun 'adult_df.sort_values(['education-num']).iloc[1:32561:1200]', study the results and explain what the code does.\n",
    "    f)\tCompare your answer to c) and what you learned from e). Was the order you came up with in c) correct?\n",
    "    g)\tEducation is an ordinal attribute, translating an ordinal attribute from an analytic perspective to a programming perspective involves choosing between Boolean representation, string representation, and integer representation. Choose which choice has been made for the three following representations of the attribute education.\n",
    "        - 'adult_df.education'\n",
    "        - 'pd.get_dummies(adult_df.education)'\n",
    "        - 'adult_df[‘education’]'\n",
    "    h)\tEither of the choices has some advantages and some disadvantages. Select which programing data representation each statement below describes. \n",
    "        - If an ordinal attribute is presented using this programming value representation, no bias or assumptions are added to the data, but algorithms that work with numbers cannot use the attribute. \n",
    "        - If an ordinal attribute is presented using this programming value representation, the data can be used by algorithms that only take numbers, but the size of the data becomes bigger and there may be concerns for computational costs.\n",
    "        - If an ordinal attribute is presented using this programming value representation, there will be no size or computational concerns, but some statistical information that may not be true is assumed and it may create bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
